{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "COVERAGE = 0.98\n",
    "DATA_FOLDER = FILE_PATH(PREPROCESSED)\n",
    "MERGED_TXT_name = \"merged_{streamer}.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer = 'kimdoe'\n",
    "model = 'word'\n",
    "size = 1000\n",
    "filename = f'sp_{streamer}_{model}_{size}_0.98.model'\n",
    "\n",
    "a = FILE_PATH(PREPROCESSED, streamer, model, filename)\n",
    "a = str(a)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6737 vs 66260\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1444993699.csv, 마작\n",
    "1447862984.csv, 마작\n",
    "1448780047.csv, 마작\n",
    "1449697088.csv, 마작\n",
    "1450736462.csv, 마작\n",
    "1453664423.csv, 마작\n",
    "1458716941.csv, 마작\n",
    "'''\n",
    "tarFile = \"1444993699.csv\"\n",
    "df = pd.read_csv(FILE_PATH(PREPROCESSED, streamer,'csv',tarFile ))\n",
    "\n",
    "def mkVector(string) -> np.array:\n",
    "    ids = sp.EncodeAsIds(string)\n",
    "\n",
    "    return ids\n",
    "    \n",
    "cnt = 0\n",
    "for line in df[\"preprocessed\"]:\n",
    "    k = mkVector(line)\n",
    "    if any(k):\n",
    "        # print(mkVector(line), line)\n",
    "        cnt += 1\n",
    "    # if cnt > 100:\n",
    "    #     break\n",
    "print(f\"{cnt} vs {len(df['preprocessed'])}\")\n",
    "\n",
    "# df[\"sp_1000_word\"] =  df[\"preprocessed\"].apply(lambda line : mkVector(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aaaa= [\n",
    "    \"1444993699.csv\",\n",
    "    \"1447862984.csv\", \n",
    "    \"1448780047.csv\", \n",
    "    \"1449697088.csv\", \n",
    "    \"1450736462.csv\", \n",
    "    \"1453664423.csv\", \n",
    "    \"1458716941.csv\",\n",
    "]\n",
    "\n",
    "ppp = \"target.txt\"\n",
    "\n",
    "savee = []\n",
    "\n",
    "for aaa in aaaa:\n",
    "    k = FILE_PATH(PREPROCESSED, streamer,'csv', aaa)\n",
    "    for ll in pd.read_csv(k)[\"preprocessed\"].to_list():\n",
    "        savee.append(ll.strip('\"\"'))\n",
    "\n",
    "with open(ppp , mode='w', encoding='utf-8') as fp:\n",
    "    fp.writelines('\\n'.join(savee)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~unigram~~~~~~~\n",
      "60028 vs 66260 | 90.59%\n",
      "41948 vs 66260 | 63.31%\n",
      "~~~~~~~~word~~~~~~~~\n",
      "33084 vs 66260 | 49.93%\n",
      "19726 vs 66260 | 29.77%\n",
      "~~~~~~~~bpe~~~~~~~~~\n",
      "60028 vs 66260 | 90.59%\n",
      "41948 vs 66260 | 63.31%\n",
      "~~~~~~~~char~~~~~~~~\n",
      "60028 vs 66260 | 90.59%\n",
      "41948 vs 66260 | 63.31%\n"
     ]
    }
   ],
   "source": [
    "tarFile = \"1444993699.csv\"\n",
    "df = pd.read_csv(FILE_PATH(PREPROCESSED, streamer,'csv',tarFile ))\n",
    "\n",
    "cnt = 0\n",
    "cnt2 = 0\n",
    "Size= 4000\n",
    "for model in ['unigram', 'word', 'bpe', 'char']:\n",
    "    cnt = 0\n",
    "    cnt2= 0\n",
    "    print(model.center(20, '~'))\n",
    "    # sp_kimdoe_char_1000_0.98.vocab\n",
    "\n",
    "    a = FILE_PATH(PREPROCESSED, streamer, model, f\"sp_{streamer}_{model}_{Size}_0.98.model\")\n",
    "    # sp.Load(f'target_{model}.model')\n",
    "    sp.Load(str(a))\n",
    "    for line in df[\"preprocessed\"]:\n",
    "        k = sp.EncodeAsIds(line.strip('\"'))\n",
    "        # print(k, line.strip('\"'), sp.DecodeIds(k), line.strip('\"')==sp.DecodeIds(k).strip())\n",
    "        if line.strip('\"')==sp.DecodeIds(k).strip():\n",
    "            cnt2 +=1\n",
    "        if all(k):\n",
    "            # print(mkVector(line), line)\n",
    "            cnt += 1\n",
    "        # if cnt > 100:\n",
    "        #     break\n",
    "    print(f\"{cnt} vs {len(df['preprocessed'])} | {cnt / len(df['preprocessed'])*100:.2f}%\")\n",
    "    print(f\"{cnt2} vs {len(df['preprocessed'])} | {cnt2 / len(df['preprocessed'])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarFile = \"1444993699.csv\"\n",
    "\n",
    "modelFile = FILE_PATH(PREPROCESSED, streamer,'unigram','sp_kimdoe_unigram_4000_0.98.model' )\n",
    "\n",
    "sp.Load(f'{modelFile}')\n",
    "\n",
    "sentences = list(pd.read_csv(FILE_PATH(PREPROCESSED, streamer,'csv',tarFile ))[\"preprocessed\"])\n",
    "\n",
    "ii = [ x for x in map(lambda x : sp.EncodeAsIds(x.strip('\"')), sentences)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'unigram'\n",
    "vocabSize = 1000\n",
    "\n",
    "# vv = list()\n",
    "# for ee in ii:   \n",
    "#     t = np.zeros(vocabSize)\n",
    "#     for index in ee:\n",
    "#         t[index] += 1.0\n",
    "#     vv.append(t)\n",
    "# vvv = np.array(vv)\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA(n_components=50)\n",
    "model.fit(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.explained_variance_ratio_)\n",
    "data = model.fit_transform(vvv)\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(data)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 11271, 3: 21787, 0: 22189, 1: 551, 2: 10462})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label  =KMeans(5).fit_predict(data)\n",
    "import collections\n",
    "collections.Counter(label)\n",
    "# for i in range(8):\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILE_PATH(PREPROCESSED, streamer,'csv',tarFile ))\n",
    "\n",
    "df['cluster'] = label\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "i=0\n",
    "for u , x in enumerate(df[df['cluster'] == i]['preprocessed']):\n",
    "    print(x.strip('\"'))\n",
    "    # if u >300:\n",
    "print(\"========================\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "for u , x in enumerate(df[df['cluster'] == i]['preprocessed']):\n",
    "    print(x.strip('\"'))\n",
    "    # if u >300:\n",
    "print(\"========================\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2\n",
    "for u , x in enumerate(df[df['cluster'] == i]['preprocessed']):\n",
    "    print(x.strip('\"'))\n",
    "    # if u >300:\n",
    "print(\"========================\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=3\n",
    "for u , x in enumerate(df[df['cluster'] == i]['preprocessed']):\n",
    "    print(x.strip('\"'))\n",
    "    # if u >300:\n",
    "print(\"========================\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=4\n",
    "for u , x in enumerate(df[df['cluster'] == i]['preprocessed']):\n",
    "    print(x.strip('\"'))\n",
    "    # if u >300:\n",
    "print(\"========================\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=5\n",
    "for u , x in enumerate(df[df['cluster'] == i]['preprocessed']):\n",
    "    print(x.strip('\"'))\n",
    "    # if u >300:\n",
    "print(\"========================\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "oktDict = FILE_PATH('preprocessed', 'kimdoe', 'dict_okt.pickle')\n",
    "mecabDict = FILE_PATH('preprocessed', 'kimdoe', 'dict_mecab.pickle')\n",
    "with open(oktDict, mode='rb') as fp:\n",
    "    a = pickle.load(fp)\n",
    "    t = sorted(a.items(), key = lambda x:x[1], reverse=True)\n",
    "    \n",
    "    for k, v in t:\n",
    "        if v < 100:\n",
    "            break\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b3ac0276949964df410688d0b1c021e8422dbc8d7438159d38a17327ff0b85b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
